---
# mid training
#  add vflan
#  add coyo_25m_wds 30%
#  add larger sized projector
doc_mid15:
    - docmatix_2
    - docmatix_3
    - pdfa-1m
    - allava_caption_vflan
    - unichart-pretrain-1m
    - mtwi
    - art1

vila10_pretrain:
    - llava_1_5_mm_align
    - ccs_recaptioned

coyowds_25m:
    - coyo_25m_wds_spatial_ocr_bbox_interleaved_qas

# pretrain dataset
cvpr_v20:
    - sharegpt4v_pretrain
    - coyo_25m_wds_spatial_ocr_bbox_interleaved_qas
    - docmatix_750k
    - mmc4core_10_subset
    
eagle_stage15:
    - eagle/GroundUI
    - eagle/HME100K
    - eagle/IAM_words_text_recognition
    - eagle/IMGUR5K
    - eagle/Infinity-Instruct
    - eagle/MMDU
    - eagle/MMInstruct_cn
    - eagle/MMInstruct_qa
    - eagle/MTVQA
    - eagle/NuminaMath-CoT
    - eagle/ORAND_CAR
    - eagle/OpenMathInstruct
    - eagle/PDF_VQA
    - eagle/RLAIF-V
    - eagle/SPARK
    - eagle/SQuAD_VQA
    - eagle/SlideVQA
    - eagle/StepDPO
    - eagle/TAL_HW_MATH
    - eagle/TAL_OCR_ENG
    - eagle/TAT_DQA
    - eagle/UltraInteract_sft
    - eagle/UniGeo
    - eagle/VQA_CD
    - eagle/VQAonBD
    - eagle/VisualWebInstruct
    - eagle/ai2d
    - eagle/ai2d_gpt
    - eagle/alfworldgpt
    - eagle/allava_laion
    - eagle/allava_vflan
    - eagle/animals
    - eagle/art_ocr
    - eagle/arxivqa
    - eagle/benthamQA
    - eagle/block_digram
    - eagle/captcha
    - eagle/cauldron_ai2d
    - eagle/cauldron_aokvqa
    - eagle/cauldron_cocoqa
    - eagle/cauldron_diagram_image_to_text
    - eagle/cauldron_geomverse
    - eagle/cauldron_hateful_memes
    - eagle/cauldron_iam
    - eagle/cauldron_iconqa
    - eagle/cauldron_intergps
    - eagle/cauldron_intergps_gpt
    - eagle/cauldron_mapqa
    - eagle/cauldron_mimic_cgd
    - eagle/cauldron_multihiertt
    - eagle/cauldron_nlvr2
    - eagle/cauldron_ocrvqa
    - eagle/cauldron_raven
    - eagle/cauldron_raven_2
    - eagle/cauldron_rendered_text
    - eagle/cauldron_robut_sqa
    - eagle/cauldron_robut_wikisql
    - eagle/cauldron_robut_wtq
    - eagle/cauldron_spot_the_diff
    - eagle/cauldron_st_vqa
    - eagle/cauldron_vistext
    - eagle/cauldron_visual7w
    - eagle/cauldron_visualmrc
    - eagle/cauldron_vqarad
    - eagle/cauldron_websight
    - eagle/cc3m_recap
    - eagle/chart2text
    - eagle/chartqa
    - eagle/chartqa_aug
    - eagle/chartqa_aug_yn
    - eagle/chartqa_qwen_max_cot
    - eagle/chinese_meme
    - eagle/chrome_writting
    - eagle/clevr
    - eagle/clevr_math
    - eagle/clevr_math_qwenvl_cot
    - eagle/code_feedback
    - eagle/colors
    - eagle/colpali
    - eagle/ctw
    - eagle/datikz
    - eagle/deepfusion
    - eagle/design2code
    - eagle/digit_handwritten_latex
    - eagle/docmatrix
    - eagle/docmatrix_2pages
    - eagle/docreason
    - eagle/docvqa
    - eagle/docvqa_cot
    - eagle/docvqa_text
    - eagle/dvqa
    - eagle/est_vqa
    - eagle/face_emotion
    - eagle/figureqa
    - eagle/financeqa
    - eagle/geo
    - eagle/geos
    - eagle/geos_gpt
    - eagle/gpt_cauldron_raven
    - eagle/gpt_chartqa
    - eagle/gpt_cocotext
    - eagle/gpt_ctw
    - eagle/gpt_funsd
    - eagle/gpt_hiertext
    - eagle/gpt_infovqa
    - eagle/gpt_landmark
    - eagle/gpt_lvst
    - eagle/gpt_maptext
    - eagle/gpt_mtwi
    - eagle/gpt_nfv5
    - eagle/gpt_rects
    - eagle/gpt_roadtext
    - eagle/gpt_sroie
    - eagle/gpt_tqa
    - eagle/gpt_ureader
    - eagle/gpt_wikiart
    - eagle/gqa
    - eagle/handwriting_forms
    - eagle/handwriting_latex
    - eagle/i2s-musicsheet
    - eagle/idk
    - eagle/iiit5k
    - eagle/iiit5k_aug
    - eagle/image_textualization
    - eagle/indoor_qa
    - eagle/infinitymath
    - eagle/infos_v1
    - eagle/infos_v2
    - eagle/infovqa
    - eagle/invoice
    - eagle/k12_ext
    - eagle/k12_printing
    - eagle/koniq
    - eagle/koniq2
    - eagle/kvqa
    - eagle/latex_formula
    - eagle/liaion_gpt4v
    - eagle/llava-critic-113k
    - eagle/llava_instruct_150k
    - eagle/llava_instruct_150k_zh
    - eagle/llavar
    - eagle/lnqa
    - eagle/lrv_chart
    - eagle/lvis_instruct4v
    - eagle/mathinstruct
    - eagle/mathvision
    - eagle/mathvision_cot
    - eagle/mavis_math_metagen
    - eagle/mavis_math_metagen_cot
    - eagle/mavis_math_rule_geo
    - eagle/md_arxiv
    - eagle/memes
    - eagle/memotion
    - eagle/meta_mathqa
    - eagle/mmc_inst
    - eagle/mmra
    - eagle/movie_posters
    - eagle/music
    - eagle/object365_coordinate_train_coord_detect_all
    - eagle/object365_exists_train_exist
    - eagle/object365_exists_train_exist_logic
    - eagle/ocra
    - eagle/oodvqa
    - eagle/openhermes
    - eagle/orca_math
    - eagle/pathvqa
    - eagle/place365
    - eagle/plotqa
    - eagle/pmc_vqa
    - eagle/python_code_25k
    - eagle/python_code_instructions_18k_alpaca
    - eagle/recipe
    - eagle/rects
    - eagle/ref3coco
    - eagle/refcocog
    - eagle/ruozhiba
    - eagle/sam_77k
    - eagle/scale_nv
    - eagle/scienceqa
    - eagle/scienceqa_onevision
    - eagle/sciqa
    - eagle/screenqa
    - eagle/sft_zh
    - eagle/sharegpt4o
    - eagle/sharegpt4v100k
    - eagle/sharegpt4v665k
    - eagle/sketchyvqa
    - eagle/sketchyvqa_8k_qwenvl_cot
    - eagle/spatialsense
    - eagle/sroie
    - eagle/super_clevr
    - eagle/svrd
    - eagle/synthdog
    - eagle/tab_mwp
    - eagle/tablellm
    - eagle/tallyqa
    - eagle/textbooks_nv
    - eagle/textcaps
    - eagle/textocr_gpt4v
    - eagle/textvqa
    - eagle/textvqa_text
    - eagle/theoremqa
    - eagle/theoremqa_gpt
    - eagle/tmdb-celeb-10k
    - eagle/tqa
    - eagle/unichart
    - eagle/ureader
    - eagle/video_order
    - eagle/viquae
    - eagle/vqav2
    - eagle/vqav2_ext
    - eagle/vsr
    - eagle/wds_second_iteration_v3
    - eagle/weather
    - eagle/wikiart_type
    - eagle/wildvision
    - eagle/wizardlm
    - eagle/wordart
    - eagle/wordart_grid


gemini_thinking_data:
    - thinking/unichart
    - thinking/llave_onevision_images_sft
    - thinking/chartqa_train_18k
    - thinking/tabmwp

j63_recipe:
    - sharegpt4v_gpt4_100k
    - llava_instruct
    - sharegpt4v_sft
    - dvqa_train_200k
    - chartqa_train_18k
    - ai2d_train_12k
    - docvqa_train_10k
    - geoqa
    - synthdog_en

v13_mmmu_v20:
    - sharegpt4v_gpt4_100k
    - llava_instruct
    - sharegpt4v_sft
    - dvqa_train_200k
    - chartqa_train_18k_cot2
    - ai2d_train_12k
    - docvqa_train_10k
    - geoqa
    - synthdog_en
    - scienceqa
    - wit_subset
    - math
    - sherlock
    - idefics2_sft
    - llave_onevision_images_sft_cot2
    - cambrian_1375k
    - stem_qa
    - nv_mm_sft
    - vflan_no_video
    - shikra
    - lrv_instruction
    - textocr_qa
    - mmc_instruction
    - unimm_chat
    - svit
    - mmbench_val
    - cvbench
    - doc_reason
    - mtwi
    - kvqa
    - art
    - mimicvqa
    - slake
    - medvqa
    - pathvqa
    - tabmwp_cot
    - grandstaff_qa
    - chembl
    - estvqa
    - poie
    - sroie
    - ureaderkg
    - real-cqa
    - mminstruct
    - unichart
    - wordart
    - orand-b
    - olmo_doc_table
    - olmo_doc_doc
    - olmo_doc_diagrams
    - olmo_doc_charts
    - olmo_clock200k
    - olmo_askanything
    - sroie

v13_mmmu_v12_nocot:
    - sharegpt4v_gpt4_100k
    - llava_instruct
    - sharegpt4v_sft
    - dvqa_train_200k
    - chartqa_train_18k
    - ai2d_train_12k
    - docvqa_train_10k
    - geoqa
    - synthdog_en
    - scienceqa
    - wit_subset
    - math
    - sherlock
    - idefics2_sft
    - llave_onevision_images_sft
    - cambrian_1375k
    - stem_qa
    - nv_mm_sft
    - vflan_no_video
    - shikra
    - lrv_instruction
    - textocr_qa
    - mmc_instruction
    - unimm_chat
    - svit
    - mmbench_val
    - cvbench
    - doc_reason
    - mtwi
    - kvqa
    - art
    - mimicvqa
    - slake
    - medvqa
    - pathvqa
    - tabmwp_cot
    - grandstaff_qa
    - chembl
    - estvqa
    - poie
    - sroie
    - ureaderkg
    - real-cqa
    - mminstruct
    - unichart
    - wordart
    - orand-b
    - olmo_doc_table
    - olmo_doc_doc
    - olmo_doc_diagrams
    - olmo_doc_charts
    - olmo_clock200k
    - olmo_askanything
    - sroie

v13_mmmu_v12:
    - sharegpt4v_gpt4_100k
    - llava_instruct
    - sharegpt4v_sft_cot5
    - dvqa_train_200k_cot5
    - chartqa_train_18k_cot2
    - ai2d_train_12k
    - docvqa_train_10k_cot5
    - geoqa
    - synthdog_en
    - scienceqa
    - wit_subset
    - math
    - sherlock
    - idefics2_sft
    - llave_onevision_images_sft_cot5
    - cambrian_1375k
    - stem_qa
    - nv_mm_sft
    - vflan_no_video
    - shikra
    - lrv_instruction
    - textocr_qa
    - mmc_instruction
    - unimm_chat
    - svit
    - mmbench_val
    - cvbench
    - doc_reason
    - mtwi
    - kvqa
    - art
    - mimicvqa
    - slake
    - medvqa
    - pathvqa
    - tabmwp_cot
    - grandstaff_qa
    - chembl
    - estvqa
    - poie
    - sroie
    - ureaderkg
    - real-cqa_cot5
    - mminstruct
    - unichart_cot5
    - wordart
    - orand-b
    - olmo_doc_table
    - olmo_doc_doc
    - olmo_doc_diagrams
    - olmo_doc_charts
    - olmo_clock200k
    - olmo_askanything
    - sroie

cvpr_mmmu_v13_5M:
    - sharegpt4v_gpt4_100k@0.5
    - llava_instruct@0.5
    - sharegpt4v_sft@0.5_gqa
    - dvqa_train_200k@0.5
    - chartqa_train_18k_cot2
    - ai2d_train_12k
    - docvqa_train_10k
    - geoqa@0.5
    - synthdog_en@0.5
    - scienceqa
    - wit_subset@0.5
    - math@0.5
    - sherlock@0.5
    - idefics2_sft@0.5
    - llave_onevision_images_sft_cot2
    - cambrian_1375k@0.5
    - stem_qa@0.5
    - nv_mm_sft@0.5
    - captioning_image-paragraph-captioning_train@0.5
    - captioning_textcap_train@0.5
    - generation_visual-dialog_train@0.5
    - reasoning_clevr_train@0.5
    - reasoning_nlvr_train@0.5
    - reasoning_visual-mrc_train@0.5
    - vqa_docvqa_train
    - vqa_gqa_train
    - vqa_ivqa_train@0.5
    - vqa_ocr-vqa_train@0.5
    - vqa_st-vqa_train@0.5
    - vqa_viquae_train@0.5
    - vqa_vqa-v2_train@0.5
    - shikra@0.5
    - lrv_instruction@0.5
    - textocr_qa@0.5
    - mmc_instruction@0.5
    - unimm_chat@0.5
    - svit@0.5
    - mmbench_val
    - cvbench
    - doc_reason@0.5
    - mtwi
    - kvqa
    - art@0.5
    - mimicvqa@0.5
    - slake@0.5
    - medvqa@0.5
    - pathvqa@0.5
    - tabmwp_cot
    - grandstaff_qa@0.5
    - chembl@0.5
    - estvqa
    - poie
    - sroie
    - ureaderkg@0.5
    - real-cqa@0.5
    - mminstruct@0.5
    - unichart@0.5
    - wordart
    - orand-b
    - olmo_doc_table@0.5
    - olmo_doc_doc@0.5
    - olmo_doc_diagrams@0.5
    - olmo_doc_charts@0.5
    - olmo_clock200k@0.5
    - olmo_askanything@0.5

llava-video-sft:
    - llava-video/academic-cap
    - llava-video/academic-mc
    - llava-video/academic-oe
    - llava-video/activitynetqa-oe
    - llava-video/nextqa-mc
    - llava-video/nextqa-oe
    - llava-video/perceptiontest-mc
    - llava-video/sharegptvideo-cap
    - llava-video/sharegptvideo-oe
    - llava-video/youtube-cap
    - llava-video/youtube-mc
    - llava-video/youtube-oe

recipe_v13:
    - sharegpt4v_gpt4_100k
    - llava_instruct
    - sharegpt4v_sft
    - dvqa_train_200k
    - chartqa_train_18k
    - ai2d_train_12k
    - docvqa_train_10k
    - geoqa
    - synthdog_en
    - scienceqa
    - wit_subset
    - math
    - sherlock
    - idefics2_sft
    - llave_onevision_images_sft
    - cambrian_1375k
    - shot2story_shotonly
    - video_chatgpt
    - youcook2
    - sharegpt_video
    - stem_qa
    - nv_mm_sft
    - jukinmedia
    - sharegpt4video
    - k710
    - ssv2
    - reason_clevrerqa
    - reason_clevrermc
    - vcg_human
    - video_chat1
    # - av_llava_4785
    - vflan
    - refcoco_train
    - shikra
    - lrv_instruction
    - textocr_qa
    - mmc_instruction
    - m4-instruct-video
    - nextqa_mc
    - unimm_chat
    - svit
    - mmbench_val
    - cvbench
    - m4-instruct-image-nuscenes
    - webvid_qa
    # - caption_videochat
    - doc_reason
    - metamathqa
    - mminstruct
    - unichart
    - mtwi
    - kvqa

# filtering 1829303 of 6883312, 27% reduction
recipe_v9_no_video_30:
    - sharegpt4v_gpt4_100k@30
    - llava_instruct@30
    - sharegpt4v_sft@30
    - dvqa_train_200k
    - chartqa_train_18k@30
    - ai2d_train_12k@30
    - docvqa_train_10k@30
    - geoqa@30
    - synthdog_en@30
    - scienceqa@30
    - wit_subset@30
    - math
    - sherlock@30
    - idefics2_sft@30
    - llave_onevision_images_sft@30
    - cambrian_1375k@30
    - stem_qa@30
    - nv_mm_sft@30
    - k710
    - ssv2
    - reason_clevrerqa
    - reason_clevrermc
    - vcg_human
    - vflan
    - refcoco_train@30
    - shikra@30
    - lrv_instruction
    - textocr_qa@30
    - mmc_instruction@30
    - nextqa_mc
    - unimm_chat@30
    - svit@30
    - mmbench_val@30
    - cvbench@30

# filtering 2732497 of 6883312, 40% reduction
recipe_v9_no_video_20:
    - sharegpt4v_gpt4_100k@20
    - llava_instruct@20
    - sharegpt4v_sft@20
    - dvqa_train_200k
    - chartqa_train_18k@20
    - ai2d_train_12k@20
    - docvqa_train_10k@20
    - geoqa@20
    - synthdog_en@20
    - scienceqa@20
    - wit_subset@20
    - math
    - sherlock@20
    - idefics2_sft@20
    - llave_onevision_images_sft@20
    - cambrian_1375k@20
    - stem_qa@20
    - nv_mm_sft@20
    - k710
    - ssv2
    - reason_clevrerqa
    - reason_clevrermc
    - vcg_human
    - vflan
    - refcoco_train@20
    - shikra@20
    - lrv_instruction
    - textocr_qa@20
    - mmc_instruction@20
    - nextqa_mc
    - unimm_chat@20
    - svit@20
    - mmbench_val@20
    - cvbench@20

recipe_v9_no_video:
    - sharegpt4v_gpt4_100k
    - llava_instruct
    - sharegpt4v_sft
    - dvqa_train_200k
    - chartqa_train_18k
    - ai2d_train_12k
    - docvqa_train_10k
    - geoqa
    - synthdog_en
    - scienceqa
    - wit_subset
    - math
    - sherlock
    - idefics2_sft
    - llave_onevision_images_sft
    - cambrian_1375k
    - stem_qa
    - nv_mm_sft
    - k710
    - ssv2
    - reason_clevrerqa
    - reason_clevrermc
    - vcg_human
    - vflan
    - refcoco_train
    - shikra
    - lrv_instruction
    - textocr_qa
    - mmc_instruction
    - nextqa_mc
    - unimm_chat
    - svit
    - mmbench_val
    - cvbench

recipe_v9:
    - sharegpt4v_gpt4_100k
    - llava_instruct
    - sharegpt4v_sft
    - dvqa_train_200k
    - chartqa_train_18k
    - ai2d_train_12k
    - docvqa_train_10k
    - geoqa
    - synthdog_en
    - scienceqa
    - wit_subset
    - math
    - sherlock
    - idefics2_sft
    - llave_onevision_images_sft
    - cambrian_1375k
    - shot2story_shotonly
    - video_chatgpt
    - youcook2
    - vatex
    - sharegpt_video
    - stem_qa
    - nv_mm_sft
    - jukinmedia
    - sharegpt4video
    - k710
    - ssv2
    - reason_clevrerqa
    - reason_clevrermc
    - vcg_human
    - video_chat1
    - av_llava_4785
    - vflan
    - refcoco_train
    - shikra
    - lrv_instruction
    - textocr_qa
    - mmc_instruction
    - m4-instruct-video
    - nextqa_mc
    - unimm_chat
    - svit
    - mmbench_val
    - cvbench

vflan:
    - captioning_image-paragraph-captioning_train
    - captioning_msrvtt_train
    - captioning_textcap_train
    - generation_visual-dialog_train
    - reasoning_clevr_train
    - reasoning_nlvr_train
    - reasoning_visual-mrc_train
    - text_flan_1m
    - vqa_activitynet-qa_train
    - vqa_docvqa_train
    - vqa_gqa_train
    - vqa_ivqa_train
    - vqa_msrvtt-qa_train
    - vqa_msvd-qa_train
    - vqa_ocr-vqa_train
    - vqa_st-vqa_train
    - vqa_viquae_train
    - vqa_vqa-v2_train

vflan_no_video:
    - captioning_image-paragraph-captioning_train
    - captioning_textcap_train
    - generation_visual-dialog_train
    - reasoning_clevr_train
    - reasoning_nlvr_train
    - reasoning_visual-mrc_train
    - vqa_docvqa_train
    - vqa_gqa_train
    - vqa_ivqa_train
    - vqa_ocr-vqa_train
    - vqa_st-vqa_train
    - vqa_viquae_train
    - vqa_vqa-v2_train

vflan_no_video_no_docvqa:
    - captioning_image-paragraph-captioning_train
    - captioning_textcap_train
    - generation_visual-dialog_train
    - reasoning_clevr_train
    - reasoning_nlvr_train
    - reasoning_visual-mrc_train
    - vqa_gqa_train
    - vqa_ivqa_train
    - vqa_ocr-vqa_train
    - vqa_st-vqa_train
    - vqa_viquae_train
    - vqa_vqa-v2_train

vila-v1.5-sft:
    - ai2d_train_12k
    - chartqa_train_18k
    - docvqa_train_10k
    - dvqa_train_200k
    - geoqa
    - llava_instruct
    - math
    - scienceqa
    - sharegpt4v_gpt4_100k
    - sharegpt4v_sft
    - sharegpt_video
    - sherlock
    - shot2story_shotonly
    - synthdog_en
    - vatex
    - vflan
    - video_chatgpt
    - wit_subset
    - youcook2

slice-0.3:
    - sharegpt4v_sft@0.3
    - captioning_image-paragraph-captioning_train@0.3
    - captioning_msrvtt_train@0.3
    - captioning_textcap_train@0.3
    - generation_visual-dialog_train@0.3
    - reasoning_clevr_train@0.3
    - reasoning_nlvr_train@0.3
    - reasoning_visual-mrc_train@0.3
    - text_flan_1m@0.3
    - vqa_activitynet-qa_train@0.3
    - vqa_docvqa_train@0.3
    - vqa_gqa_train@0.3
    - vqa_ivqa_train@0.3
    - vqa_msrvtt-qa_train@0.3
    - vqa_msvd-qa_train@0.3
    - vqa_ocr-vqa_train@0.3
    - vqa_st-vqa_train@0.3
    - vqa_viquae_train@0.3
    - vqa_vqa-v2_train@0.3

molmo:
    - ask_model_anything
    - documents_charts
    - documents_tables
    - pointing_qa
    - capqa
    - documents_diagrams
    - pointing_high_frequency
    - clocks_processed_200k
    - documents_documents
    - pointing

molmo_0.1:
    - ask_model_anything@0.1
    - documents_charts@0.1
    - documents_tables@0.1
    - pointing_qa@0.1
    - capqa@0.1
    - documents_diagrams@0.1
    - pointing_high_frequency@0.1
    - clocks_processed_200k@0.1
    - documents_documents@0.1
    - pointing@0.1

sharegpt_llava_dv_chart_a12d_doc_geo_synthdog:
    - sharegpt4v_gpt4_100k
    - sharegpt4v_sft
    - llava_instruct
    - dvqa_train_200k
    - chartqa_train_18k
    - ai2d_train_12k
    - docvqa_train_10k
    - geoqa
    - synthdog_en
